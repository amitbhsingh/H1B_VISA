{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "https://www.kaggle.com/autuanliuyc/logistic-regression-with-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fun(x):\n",
    "    x=tf.matmul(x,x)\n",
    "    print(x)\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "py_func() missing 1 required positional argument: 'Tout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6fe17904b168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: py_func() missing 1 required positional argument: 'Tout'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x=tf.placeholder(dtype=tf.float32)\n",
    "    pf=tfe.py_func(my_fun, [x])\n",
    "    sess.run(pf,feed_dict={x:[[2.0]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris_df=datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-54-835cda9607fa>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-835cda9607fa>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    print(\"loss_train=%f, loss_test=%f, accurarcy_train=%f, accurary_test=%f\" % (train_loss, test_loss, train_accuracy, test_accuracy)\u001b[0m\n\u001b[0m                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "nfeatures = 123\n",
    "inputs_placeholder = tf.placeholder(tf.float32, [None, nfeatures], name=\"inputs\")\n",
    "labels_placeholder = tf.placeholder(tf.float32, [None], name=\"labels\")\n",
    "\n",
    "with tf.name_scope('inference') as scope:\n",
    "  W = tf.Variable(tf.zeros([nfeatures,1], tf.float32), name=\"W\")\n",
    "  b = tf.Variable(tf.zeros([1], tf.float32), name=\"b\")\n",
    "  outputs = tf.sigmoid(tf.to_double(tf.reduce_sum(tf.matmul(inputs_placeholder, W), [1]) + b))\n",
    "  predictions = tf.greater_equal(outputs, 0.5)\n",
    "\n",
    "with tf.name_scope('loss') as scope:\n",
    "  loss_tmp = - tf.to_double(labels_placeholder) * tf.log(outputs) - (1.0 - tf.to_double(labels_placeholder)) * tf.log(1.0 - outputs)\n",
    "  #loss = tf.reduce_sum(tf.to_float(loss_tmp))\n",
    "  loss = tf.reduce_mean(tf.to_float(loss_tmp))\n",
    "\n",
    "with tf.name_scope('train') as scope:\n",
    "  learning_rate = 0.05\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  train_step = optimizer.minimize(loss)\n",
    "\n",
    "def readfile(fname):\n",
    "  labels = []\n",
    "  data = []\n",
    "  with open(fname) as f:\n",
    "    for line in f:\n",
    "      xs = line.split(\" \")\n",
    "      h = [0.0] * nfeatures\n",
    "      for s in xs[1:]:\n",
    "        s = s.strip()\n",
    "        if len(s)==0:\n",
    "          continue\n",
    "        (k,v) = s.split(\":\")\n",
    "        h[int(k) - 1] = float(v)\n",
    "      data.append(h)\n",
    "      labels.append(int(xs[0]) > 0)\n",
    "  return (data, labels)\n",
    "\n",
    "# http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html#a9a\n",
    "train_data, train_labels = readfile(\"a9a\")\n",
    "test_data, test_labels = readfile(\"a9a.t\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  feed_dict_train = {inputs_placeholder: np.array(train_data), labels_placeholder: np.array([1.0 if b2 else 0.0 for b2 in train_labels])}\n",
    "  feed_dict_test  = {inputs_placeholder: np.array(test_data), labels_placeholder: np.array([1.0 if b2 else 0.0 for b2 in test_labels])}\n",
    "  sess.run(tf.initialize_all_variables())\n",
    "  for step in xrange(0, 200):\n",
    "    result = sess.run(train_step, feed_dict=feed_dict_train)\n",
    "    if step % 10 == 0:\n",
    "      train_loss, train_predictions = sess.run([loss, predictions], feed_dict=feed_dict_train)\n",
    "      test_loss, test_predictions = sess.run([loss, predictions], feed_dict=feed_dict_test)\n",
    "      train_accuracy = sum(1.0 for (y_,y) in zip(train_labels, train_predictions) if y==y_) / len(train_labels)\n",
    "      test_accuracy = sum(1.0 for (y_,y) in zip(test_labels, test_predictions) if y==y_) / len(test_labels)\n",
    "      print(\"loss_train=%f, loss_test=%f, accurarcy_train=%f, accurary_test=%f\" % (train_loss, test_loss, train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
