{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.vision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c0e76450f370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.vision'"
     ]
    }
   ],
   "source": [
    "from fastai.vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AtrousConvolution1D, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "\n",
    "import seaborn as sns\n",
    "sns.despine()\n",
    "\n",
    "\n",
    "data_original = pd.read_csv('./data/AAPL1216.csv')[::-1]\n",
    "\n",
    "openp = data_original.ix[:, 'Open'].tolist()\n",
    "highp = data_original.ix[:, 'High'].tolist()\n",
    "lowp = data_original.ix[:, 'Low'].tolist()\n",
    "closep = data_original.ix[:, 'Adj Close'].tolist()\n",
    "volumep = data_original.ix[:, 'Volume'].tolist()\n",
    "\n",
    "# data_chng = data_original.ix[:, 'Adj Close'].pct_change().dropna().tolist()\n",
    "\n",
    "WINDOW = 30\n",
    "EMB_SIZE = 5\n",
    "STEP = 1\n",
    "FORECAST = 1\n",
    "\n",
    "X, Y = [], []\n",
    "for i in range(0, len(data_original), STEP): \n",
    "    try:\n",
    "        o = openp[i:i+WINDOW]\n",
    "        h = highp[i:i+WINDOW]\n",
    "        l = lowp[i:i+WINDOW]\n",
    "        c = closep[i:i+WINDOW]\n",
    "        v = volumep[i:i+WINDOW]\n",
    "\n",
    "        o = (np.array(o) - np.mean(o)) / np.std(o)\n",
    "        h = (np.array(h) - np.mean(h)) / np.std(h)\n",
    "        l = (np.array(l) - np.mean(l)) / np.std(l)\n",
    "        c = (np.array(c) - np.mean(c)) / np.std(c)\n",
    "        v = (np.array(v) - np.mean(v)) / np.std(v)\n",
    "\n",
    "        x_i = closep[i:i+WINDOW]\n",
    "        y_i = closep[i+WINDOW+FORECAST]  \n",
    "\n",
    "        last_close = x_i[-1]\n",
    "        next_close = y_i\n",
    "\n",
    "        if last_close < next_close:\n",
    "            y_i = [1, 0]\n",
    "        else:\n",
    "            y_i = [0, 1] \n",
    "\n",
    "        x_i = np.column_stack((o, h, l, c, v))\n",
    "\n",
    "    except Exception as e:\n",
    "        break\n",
    "\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution1D(input_shape = (WINDOW, EMB_SIZE),\n",
    "                        nb_filter=16,\n",
    "                        filter_length=4,\n",
    "                        border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=8,\n",
    "                        filter_length=4,\n",
    "                        border_mode='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(BatchNormalization())\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = Nadam(lr=0.002)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=30, min_lr=0.000001, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"lolkek.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train, \n",
    "          nb_epoch = 100, \n",
    "          batch_size = 128, \n",
    "          verbose=1, \n",
    "          validation_data=(X_test, Y_test),\n",
    "          callbacks=[reduce_lr, checkpointer],\n",
    "          shuffle=True)\n",
    "\n",
    "model.load_weights(\"lolkek.hdf5\")\n",
    "pred = model.predict(np.array(X_test))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix([np.argmax(y) for y in Y_test], [np.argmax(y) for y in pred])\n",
    "\n",
    "print C / C.astype(np.float).sum(axis=1)\n",
    "\n",
    "# Classification\n",
    "# [[ 0.75510204  0.24489796]\n",
    "#  [ 0.46938776  0.53061224]]\n",
    "\n",
    "\n",
    "# for i in range(len(pred)):\n",
    "#     print Y_test[i], pred[i]\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
